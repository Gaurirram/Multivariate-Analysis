---
title: "Final Project Social Media"
output: html_document
date: "2024-04-28"
---

## About the Dataset
* This dataset captures the patterns of social media usage along with associated metrics such as mood, productivity, tiredness, and how many interview calls did an individual get etc. It provides insights into how individuals allocate their time across various social media platforms and their subjective experiences and well-being indicators. We collected this data over a period of weeks from all the students in the class where each student were recording the time spent on each of the apps and also the qualities such as mood productivity, tiredness waking up etc.

```{r}
library(readr)
library(factoextra)
library(FactoMineR)
library(magrittr)
library(NbClust)
social <- read.csv("D:/Rutgers/R2nd Semester/Multivariate/Socialmediacleaned.csv",row.names=1)

social2<-social[, c("Instagram_Hours","LinkedIn_Hours","Snapchat_Hours","Twitter_Hours","Whatsapp_Wechat_hours","Reddit_hours","Youtube_hours","OTT_hours")]
str(social2)
```

### Inference
* The above columns are the columns which shows the time spent from each individual on each of those particular apps.
* We are taking these columns to check the apps which are most used.
* The group of apps which are used together by which individuals.
* And also the apps which can be grouped together by the method of factor analysis, to see and why they can be grouped together, what do they have in common.

### EDA Analysis
### Star Plot

```{r}
stars(social2[,1:8])
```

### Inference
* Star plot helps us to check the similarity between the individual.
* We can observe that none of them are very much related, except for a few have a little similarity.

### Corelation plot

```{r}
pairs(social2[,1:8])
```

### Inference
*  Utilized the `pairs` function to create a matrix of scatter plots for pairwise attribute comparisons. The pairs plot allows you to identify patterns, correlations, and potential clusters in the data. It's useful for exploring relationships between multiple attributes simultaneously. In the visual we created above, we can see that there is not much linear corelation between the variables.

### Plot

```{r}
library(corrplot)
corrplot(cor(social2[,1:8]), type = "upper", method = "color")
```

### Inference
* The correlation plot visually represents the pairwise correlations between attributes. Positive correlations are indicated by color shades towards blue, while negative correlations are indicated by color shades towards red. The intensity of color represents the strength of the correlation. Insights can be drawn regarding which attributes tend to have a strong positive or negative relationship. We can see that none of the attributes are negatively correlated, which means if any one attribute is increasing then that does not affect any other attribute negatively. We can also see that none of the attributes are completely positively related also. 



## PCA Analysis
#### I am performing the following PCA analysis for doing dimentionality reduction and also understanding on what basis the reduction is happening.


```{r}
cor(social[, c("Instagram_Hours","LinkedIn_Hours","Snapchat_Hours","Twitter_Hours","Whatsapp_Wechat_hours","Reddit_hours","Youtube_hours","OTT_hours")])
```

### Inference
* Correlation is helping us understand, how the columns we are trying to analyze are related to each other. 
* We can observe some columns are positively correlated while some are negatively correlated.

```{r}
social_pca <- prcomp(social[, c("Instagram_Hours","LinkedIn_Hours","Snapchat_Hours","Twitter_Hours","Whatsapp_Wechat_hours","Reddit_hours","Youtube_hours","OTT_hours")],scale=TRUE)
social_pca
```

```{r}
summary(social_pca)
```

### Inference
* The above PCA analysis done shows the number of principle components our dataset can be divided into. Our data set can be divided into 8 principle components.
* As we can observe, the first four PCs explain 80% of the datasets total variance. After PC4 the increase in cumulative variance becomes less substancial for each additional component.

### ScreePlot

```{r}
library(factoextra)
(eigen_social <- social_pca$sdev^2)
names(eigen_social) <- paste("PC",2:9,sep="")

plot(eigen_social, xlab = "Component number", ylab = "Component variance", type = "l", main = "Scree diagram")

fviz_eig(social_pca, addlabels = TRUE)
```

### Inference
* The scree diagram shows us that sum of the first 3 principal components is 71.1% and tells 3 PCs should be considered.
* So, we can use PCA for column reduction as well.
* And we can also observe a significant curve shift after the third dimension.

### Biplot

```{r}
fviz_pca_var(social_pca,col.var = "cos2",
             gradient.cols = c("#FFCC00", "#CC9933", "#660033", "#330033"),
             repel = TRUE)
```

### Inference
* The distance between points in a biplot reflects the generalised distance between them.
* Correlation of the variables reflected by the angle between them. The smaller the angle, the more significant the correlation.
* For example, it shows that LinkedIn_Hours and Youtube_Hours correlated strongly.

### Individual PCA

```{r}
library(FactoMineR)
res.pca <- PCA(social2, graph = FALSE)

fviz_pca_ind(res.pca)
```

### Inference
* The students have been plotted based on their PCA values in the individual PCA plot.
* The students are allocated based on their similarities.

### PCA-biplot

```{r}
fviz_pca_biplot(res.pca, repel = TRUE,
                col.var = "#FC4E07", 
                )
```

### Inference 
* We can observe how one set of students use the apps more than the other set of students. 
* We can also observe what which apps are used common by which set of students.
* And we can also see two outliers who use certain apps more than anybody else.

### Overall PCA Analysis insights 
* For me the analysis showed that, I am an outlier from the class who used a certain type of app more than everyone else in the class, and told me which apps are those as well.
* For the entire class, it segregated them into two groups, one who use the apps for more hours compared to the other set of class who used less hours, and also tells how certain apps can be combined to form one PC and how that can in turn reduce dimentionality.

## Cluster Analysis


```{r}
matstd_social <- scale(social2)
fviz_nbclust(matstd_social, kmeans, method ="wss")+geom_vline(xintercept = 4, linetype = 2)
```

### Inference
* Cluster analysis, groups the rows into clusters based on the similarities observed between them.
* In our dataset we will be observing how students can be formed into clusters based on the similarities they have with respect to the apps they use.
* For our dataset it can be observed that ideal number of clusters is 4.

### Hierarcical Clustering

```{r}
library(magrittr)
res.hc <- matstd_social %>% scale() %>% dist(method = "euclidean") %>%
  hclust(method = "ward.D2")

fviz_dend(res.hc, k = 4, # Cut in four groups
          cex = 0.5, # label size
          k_colors = c("#2E9FDF", "#00AFBB", "#E7B800", "#FC4E07"),
          color_labels_by_k = TRUE, # color labels by groups
          rect = TRUE # Add rectangle around groups
          )
```

### Inference
* The dendogram shows how the students are divided into which cluster.

### Overall Cluster Analysis Insights
* We can observe from that, the outliers I observed in my PCA Analysis are formed into two separate clusters.
* The two sets which we observed, one set consisting of people who used the apps comparitively more than the other set.
* I was an outlier, hence I have been put into separate cluster in the cluster analysis.


### Factor Analysis

```{r}
library(psych)
attach(social2)
social2[1]
fit.pc <- principal(social2[-1], nfactors=3, rotate="varimax")
fit.pc
fa.diagram(fit.pc)
```

### Inference
* The three hidden factors are formed as shown.
* We can see that Youtube_Hours and LinkedIn_Hours are combined together maybe because people might be learning professional experience on both platforms as in to learn something in both concepts, or maybe LinkedIn for learning and Youtube for liesure.
* We can observe that OTT, Twitter and Snapchat are combined to one, because they are all giving social media entertainment.
* We can observe that whatsapp_wechat are reddit are inversely correlated, as in, if one is being used more the other is being used less.

### Over insights from Factor Analysis
* The factor analysis shows how the apps of similar usage category can be combined together and can be helpfull in dimensionality reduction.
* It tells us what apps students are using together.

### Now performing different regression techniques on my dataset to see how these columns would individually affect or help predict a predicting column such as mood productivity.

### Multiple Regression

```{r}
library(factoextra)
library(FactoMineR)
library(psych)
```

```{r}
social3<-social[, c("Instagram_Hours","LinkedIn_Hours","Snapchat_Hours","Twitter_Hours","Whatsapp_Wechat_hours","Reddit_hours","Youtube_hours","OTT_hours","Mood_Productivity")]
social3$Mood_Productivity_num <- ifelse(social3$Mood_Productivity == "Yes", 1, 0)
str(social3)
fit <- lm(Mood_Productivity_num~Instagram_Hours+LinkedIn_Hours+Snapchat_Hours+Twitter_Hours+Whatsapp_Wechat_hours+Reddit_hours+Youtube_hours+OTT_hours, data=social3)
summary(fit)

```

### Inference - Multiplr regression

* The Median being close to 0 showcases that the model is able to predict perfectly.
* Based on the residual data provided, it can be inferred that residuals may be following a Normal Distribution.
* Furthermore, it can be observed that most columns have the P-values > 0.05, which means that none of them are significantly affecting the target variable.
* However, the F-Statistic value is just above 1 which means it is a good model but not a great model.
* We can tell that the model is not that great because the significance of each individual column on the predicting column is not that high.

### Correlation plot

```{r}
library(GGally)
ggpairs(data=social3, title="Social Media Data")
```

### Inference
* The graph clearly indicates that none of the columns have a linear relationship which shows why the multiple regression model was bad.

### Logistic Regression
### Performing logistic regression to check the model performance

```{r}
library(factoextra)
library(FactoMineR)
library(psych)
library(ggplot2)
library(cowplot)
library(caret)
library(e1071)
library(pROC)
```

```{r}
social3[social3 == "?"] <- NA
social3$Mood_Productivity <- ifelse(test=social3$Mood_Productivity =="Yes", yes="Yes", no="No") 
social3$Mood_Productivity <- as.factor(social3$Mood_Productivity)
logistic_simple <- glm(Mood_Productivity ~ ., data=social3, family="binomial")
summary(logistic_simple)
```

### Inference - logistic regression
* As we can observe the p value is 1 for all the outcome variables, which means that there is a weak relationship between the predictor and outcome variable.

### Accuracy of the model

```{r}
pdata <- predict(logistic_simple,newdata=social3,type="response" )
pdataF <- as.factor(ifelse(test=as.numeric(pdata>0.5) == "Yes", yes="Yes", no="No"))
pdataF <- factor(pdataF, levels = levels(social3$Mood_Productivity))

confusionMatrix(pdataF, social3$Mood_Productivity)

```

### Inference
* The model accuracy is also shown which is 0.047, which is not a great accuracy.


### Takeaway From the overall analysis 
* From all the three type of analysis done above, we can observe the following:
* There are two sets of students in the class which was clearly clustered and diffrentiated. One which has students who spend comparitively more time on these apps and the other which comparitively spend less time on the apps.
* There are few outliers, which means they spent a lot more time on certain types of apps than others.
* We could also see which apps are being used the most together, which can be used for dimentionality reduction and better analysis.
* By performing the regression models we can see that the models performance is not that great, the variables have very less significance on the predicting variable.